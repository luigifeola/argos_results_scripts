{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:88% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:88% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import scipy.special as sc\n",
    "from scipy.stats import weibull_min\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weib_cdf(x,alpha,gamma):\n",
    "    return (1 - np.exp(-np.power(x/alpha,gamma)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_weibull(mean, std_dev, temp, popt_weibull):\n",
    "#     #fig=plt.figure(figsize=(16, 14), dpi= 80, facecolor='w', edgecolor='k')\n",
    "#     fig, ax = plt.subplots(figsize=(10, 4), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "#     '''Textbox with mu and sigma'''\n",
    "#     textstr = '\\n'.join((\n",
    "#         r'$\\mu=%.2f$' % (mean, ),\n",
    "#         r'$\\sigma=%.2f$' % (std_dev, )))\n",
    "\n",
    "#     # these are matplotlib.patch.Patch properties\n",
    "#     props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "#     # place a text box in upper left in axes coords\n",
    "#     ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=14,\n",
    "#             verticalalignment='top', bbox=props)\n",
    "\n",
    "\n",
    "#     y_weib=weib_cdf(temp,popt_weibull[0],popt_weibull[1])\n",
    "#     error_weib=np.power(y_weib-np.squeeze(F),2)\n",
    "#     plt.plot(temp,y_weib,'r',linewidth=5,label=\"Weibull Distribution\")\n",
    "#     plt.plot(temp,F,'b',linewidth=5,label=\"K-M stats\")\n",
    "#     plt.legend(loc=4)\n",
    "#     plt.ylim(0,1)\n",
    "#     #label=\"Alpha \"+str(dataset[sample,1])+\" Rho \"+str(dataset[sample,2])+\" Time of First Passage for \"+str(censored)+\"/\"+str(uncensored)+\" censored values\"\n",
    "#     label = figLabel\n",
    "#     plt.title(label)\n",
    "#     plt.xlabel(\"Number of time steps\")\n",
    "#     plt.ylabel(\"Synchronisation probability\")\n",
    "# #     plt.show()\n",
    "#     plt.savefig(figPath)\n",
    "#     plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pd_times(dirPath, experiment_type):\n",
    "    if(experiment_type!=\"times\"):\n",
    "        print(\"experiment_type could be only $times\")\n",
    "        exit(-1)\n",
    "    \n",
    "    num_experiment = len([name for name in os.listdir(dirPath) if (os.path.isfile(os.path.join(dirPath, name)) and (name.endswith('position.tsv')))])\n",
    "    \n",
    "    if(os.path.exists(dirPath+\"/\"+experiment_type+\".pkl\")):\n",
    "#         print(\"Sto cazzo di file esiste\")\n",
    "        return (num_experiment,pd.read_pickle(dirPath+\"/\"+experiment_type+\".pkl\"))\n",
    "    \n",
    "    print(\"Generating pickle times file\")\n",
    "    df = pd.DataFrame()\n",
    "    for filename in os.listdir(dirPath):\n",
    "        if filename.endswith('time_results.tsv'):\n",
    "            df_single = pd.read_csv(dirPath+\"/\"+filename, sep=\"\\t\")\n",
    "            df = df.append(df_single)\n",
    "    \n",
    "    df.to_pickle(dirPath+\"/\"+experiment_type+\".pkl\")\n",
    "    return (num_experiment,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/home/luigi/Documents/scripts/test_scripts/results/results_2020-02-17_robots_10/2020-02-14_robots#10_alpha#2.0_rho#0.0_experiment_1800/times.pkl\"\n",
    "# df = pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_convergence_time(times):\n",
    "    conv_times = np.zeros(times.shape[0])\n",
    "#     print(\"Time shape\", times.shape)\n",
    "    for idx, elem in enumerate(times):\n",
    "        if(elem[0] == 0):\n",
    "            conv_times[idx] = elem[1]\n",
    "        else:\n",
    "            conv_times[idx] = elem.min()\n",
    "    #c_time in ticks \n",
    "#     conv_time_batch = np.append(conv_time_batch, conv_times.max()) \n",
    "    return conv_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = time vector\n",
    "#censored = number o missing values\n",
    "def KM_estimator(data, censored):\n",
    "    '''K-M estimator'''\n",
    "    n_est=np.asarray(range(0,data.size))[::-1] + censored  #array from 29 to 0\n",
    "    RT_sync=[]\n",
    "    for i in range(n_est.size):\n",
    "        if len(RT_sync)==0:\n",
    "            RT_sync.append((n_est[i]-1)/n_est[i])\n",
    "        else:\n",
    "            RT_sync.append(RT_sync[-1]*((n_est[i]-1)/n_est[i]))\n",
    "#     print(RT_sync)\n",
    "    F=1-np.asarray(RT_sync).reshape(-1,1)\n",
    "#     print(F)\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weibull_plot(mean, std_dev, times_value, popt_weibull, F, figLabel, figPath):\n",
    "    fig, ax = plt.subplots(figsize=(20, 8), dpi= 160, facecolor='w', edgecolor='k')\n",
    "    '''Textbox with mu and sigma'''\n",
    "    textstr = '\\n'.join((\n",
    "        r'$\\mu=%.2f$' % (mean, ),\n",
    "        r'$\\sigma=%.2f$' % (std_dev, )))\n",
    "\n",
    "    # these are matplotlib.patch.Patch properties\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    # place a text box in upper left in axes coords\n",
    "    ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=14,\n",
    "            verticalalignment='top', bbox=props)\n",
    "\n",
    "\n",
    "    y_weib=weib_cdf(times_value,popt_weibull[0],popt_weibull[1])\n",
    "    error_weib=np.power(y_weib-np.squeeze(F),2)\n",
    "    plt.plot(times_value,y_weib,'r',linewidth=5,label=\"Weibull Distribution\")\n",
    "    plt.plot(times_value,F,'b',linewidth=5,label=\"K-M stats\")\n",
    "    plt.legend(loc=4)\n",
    "    plt.ylim(0,1)\n",
    "    #label=\"Alpha \"+str(dataset[sample,1])+\" Rho \"+str(dataset[sample,2])+\" Time of First Passage for \"+str(censored)+\"/\"+str(uncensored)+\" censored values\"\n",
    "    label = figLabel\n",
    "    plt.title(label)\n",
    "    plt.xlabel(\"Number of time steps\")\n",
    "    plt.ylabel(\"Synchronisation probability\")\n",
    "    #     plt.show()\n",
    "    plt.savefig(figPath)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(dictionary, title, storage_dir):\n",
    "    for key, value in dictionary.items():\n",
    "        fig=plt.figure(figsize = (12, 8), dpi=80)\n",
    "        dataFrame=pd.DataFrame.from_dict(value)\n",
    "        reversed_df=dataFrame.iloc[::-1]\n",
    "        ax=sns.heatmap(reversed_df, annot = True, fmt = \".2e\", cmap=\"viridis\")\n",
    "        ax.set_title(title+\", num_robots:%s\" % (key))\n",
    "        ax.set_ylabel(\"alpha\")\n",
    "        ax.set_xlabel(\"rho\")\n",
    "#         plt.show()\n",
    "        #Salva su file\n",
    "        file_name=title+\"_%s_robots.png\" % (key)\n",
    "        plt.savefig(storage_dir+'/'+file_name)\n",
    "    #     reversed_df.to_pickle(file_name[:-4] + \".pickle\")\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence Time alpha\n",
      "{'100': {'1.6': {}, '2.0': {}, '1.2': {}}, '50': {'1.6': {}, '1.2': {}, '2.0': {}}, '20': {'1.2': {}, '1.6': {}, '2.0': {}}, '10': {'2.0': {}, '1.2': {}, '1.6': {}}}\n",
      "FPT alpha\n",
      "{'100': {'1.6': {'0.3': [21684.8781537108, 427.32958630277386], '0.6': [17287.11334243398, 311.5570850275546], '0.0': [27133.62455448213, 607.0723188708473], '0.9': [14317.183134220051, 240.9130443683136]}, '2.0': {'0.9': [14808.394111724256, 254.53779141504526], '0.3': [27763.61467317399, 633.3981227010826], '0.0': [34771.71881905645, 866.2500405557003], '0.6': [20108.588556226896, 400.90400114246074]}, '1.2': {'0.6': [16526.983346059966, 293.54973424819093], '0.0': [21035.5808624603, 418.37762263949634], '0.3': [18804.234139656477, 357.00974229304006], '0.9': [14736.055672880886, 252.1535946578318]}}, '50': {'1.6': {'0.3': [19439.712875129695, 552.6226063970992], '0.6': [15610.447982193726, 400.07062415703956], '0.9': [12417.354121204138, 291.492883709171], '0.0': [23330.43057162276, 698.5167416550779]}, '1.2': {'0.0': [20315.494584582335, 570.580267009102], '0.9': [12684.944498619021, 289.438550238135], '0.3': [17500.95830579635, 456.6934759675743], '0.6': [15237.712813339227, 372.4414029723687]}, '2.0': {'0.3': [23966.97674971418, 745.2426535878791], '0.0': [30206.45096785301, 1035.2113970959012], '0.6': [17227.53148730665, 466.4414572087074], '0.9': [13248.939569846512, 319.6975216344184]}}, '20': {'1.2': {'0.6': [11759.009273982168, 395.5393102001444], '0.0': [16910.742562078827, 699.1202034702844], '0.3': [14417.001815165444, 558.8357525267878], '0.9': [11893.022274262477, 438.59853886663785]}, '1.6': {'0.3': [17798.3901810513, 800.4745855235786], '0.9': [10499.54658433744, 367.0714901792024], '0.6': [14390.168457205604, 626.2620458490676], '0.0': [18715.108193489592, 797.4154103153666]}, '2.0': {'0.9': [10638.586900321974, 397.02283412289654], '0.0': [29120.70194164503, 1638.9332526625537], '0.3': [20435.950771133495, 974.1044597102307], '0.6': [15629.631301420963, 699.8871535985414]}}, '10': {'2.0': {'0.3': [21134.78213437547, 1467.3895656874652], '0.0': [26976.11280315476, 2021.7591805722996], '0.6': [13941.656024559328, 775.6033436849552], '0.9': [11983.029352871674, 651.8217573274242]}, '1.2': {'0.6': [12700.067082602438, 721.5512136887126], '0.9': [11013.360521553603, 552.0106931906092], '0.3': [15247.694694786132, 910.072356796643], '0.0': [19065.61064554703, 1133.1706467955858]}, '1.6': {'0.0': [22633.092581973906, 1504.5351879623522], '0.9': [10282.70827001642, 504.89946920256216], '0.3': [18275.15606396731, 1156.321735943235], '0.6': [15325.466784718148, 978.0211795619596]}}}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    robots = [10, 20, 50, 100]\n",
    "    mean_fpt_dict = dict()\n",
    "    convergence_time_dict = dict()\n",
    "    #WARNING : you can remove convergence_time_alpha_dict using just convergence_time_dict\n",
    "    convergence_time_alpha_dict = dict()\n",
    "    mean_fpt_dict_alpha = dict()\n",
    "    #When conv_time_estimation==Flase -> fpt estimation\n",
    "    conv_time_estimation = False\n",
    "    bound_is=75000\n",
    "\n",
    "    from datetime import date\n",
    "    today = date.today()\n",
    "\n",
    "    main_folder = \"./results\"\n",
    "    folder_experiments = \"2020-05-25_simple_collision_avoidance_experiment\"\n",
    "    folder = os.path.join(main_folder, folder_experiments)\n",
    "    script_dir = os.path.abspath('')\n",
    "    results_dir = os.path.join(script_dir, 'Plots/'+folder_experiments+'/Weibull')\n",
    "\n",
    "    if not os.path.isdir(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "\n",
    "\n",
    "    conv_time_dir = os.path.join(results_dir, 'convergence_time')\n",
    "\n",
    "    ftp_dir = os.path.join(results_dir, 'first_passage_time')\n",
    "\n",
    "    if not os.path.isdir(conv_time_dir):\n",
    "        os.makedirs(conv_time_dir)\n",
    "    if not os.path.isdir(ftp_dir):\n",
    "        os.makedirs(ftp_dir)\n",
    "        \n",
    "#     for r in robots:    \n",
    "#     folder = script_dir+\"/results/results_2020-02-21_rob_%s\" %(r)\n",
    "    #folder = script_dir+\"/results/2020-05-25_simple_collision_avoidance_experiment/100_robots\"\n",
    "\n",
    "    if not os.path.isdir(folder):\n",
    "        print(\"folder is not an existing path\")\n",
    "        exit(-1)\n",
    "\n",
    "\n",
    "    for dirName, subdirList, fileList in os.walk(folder):\n",
    "        num_robots = \"0\"\n",
    "        rho = -1.0\n",
    "        alpha = -1.0\n",
    "        elements=dirName.split(\"_\")\n",
    "        for e in elements:\n",
    "            if e.startswith(\"robots\"):\n",
    "                num_robots=e.split(\"#\")[-1]\n",
    "                if(num_robots not in mean_fpt_dict):\n",
    "                    mean_fpt_dict[num_robots]=dict()\n",
    "                    convergence_time_dict[num_robots]=dict()\n",
    "                    convergence_time_alpha_dict[num_robots]=dict()\n",
    "                    mean_fpt_dict_alpha[num_robots]=dict()\n",
    "\n",
    "            if(e.startswith(\"rho\")):\n",
    "                rho=float(e.split(\"#\")[-1])\n",
    "            if(e.startswith(\"alpha\")):\n",
    "                alpha=float(e.split(\"#\")[-1])\n",
    "\n",
    "        if(num_robots == \"0\" or rho == -1.0 or alpha == -1):\n",
    "            continue\n",
    "\n",
    "    #     print(dirName)\n",
    "    #     print(num_robots)\n",
    "    #     print(mean_fpt_dict)\n",
    "\n",
    "        rho_str=str(rho)\n",
    "        alpha_str=str(alpha)\n",
    "    #     print(\"rho\", rho_str)\n",
    "    #     print(\"alpha\", alpha_str)\n",
    "        if(rho_str not in mean_fpt_dict[num_robots]):\n",
    "            mean_fpt_dict[num_robots][rho_str]=dict()\n",
    "    #         print(mean_fpt_dict)\n",
    "\n",
    "            convergence_time_dict[num_robots][rho_str]=dict()\n",
    "\n",
    "        if(alpha_str not in convergence_time_alpha_dict[num_robots]):\n",
    "            convergence_time_alpha_dict[num_robots][alpha_str]=dict()\n",
    "            mean_fpt_dict_alpha[num_robots][alpha_str]=dict()\n",
    "    #         print(total_dict)\n",
    "        #WARNING : di mettere alpha probabilmente non ce n'Ã¨ bisogno\n",
    "    #     if(alpha_str not in total_dict[num_robots][rho_str]):\n",
    "    #         total_dict[num_robots][rho_str][alpha_str]=dict()\n",
    "    #         mean_fpt_dict[num_robots][rho_str][alpha_str]=dict()\n",
    "    #         convergence_time_dict[num_robots][rho_str][alpha_str]=dict()\n",
    "\n",
    "\n",
    "        (num_experiment, df) = load_pd_times(dirName, \"times\")\n",
    "\n",
    "\n",
    "        df_times = df.values[:,1:]\n",
    "        convergence_times = evaluate_convergence_time(df_times)\n",
    "    #     print(dirName)\n",
    "    #     print(convergence_times.shape)\n",
    "\n",
    "\n",
    "    #     print(df_times.shape)\n",
    "    #     print(\"num experiments: \", num_experiment)\n",
    "\n",
    "\n",
    "        if(conv_time_estimation):\n",
    "            '''Weibull distribution for Convergence Time'''\n",
    "\n",
    "            #get the time in whitch each robot has at least info about the target\n",
    "            convergence_time_batches = np.amax(convergence_times.reshape(num_experiment,-1) , axis=1) \n",
    "    #         print(dirName)\n",
    "\n",
    "            #order convergence_time_batches in increasing order\n",
    "            convergence_time_batches = convergence_time_batches[np.argsort(convergence_time_batches)]\n",
    "    #         print(convergence_time_batches.shape)\n",
    "    #         print(convergence_time_batches)\n",
    "            figPath = conv_time_dir+'/'+\"conv_time_robots_%s_alpha_%s_rho_%s.png\" % (num_robots, alpha_str, rho_str) \n",
    "            figLabel = \"Convergence Time robots:%s alpha:%s, rho:%s.png\" % (num_robots, alpha_str, rho_str)\n",
    "    #         censored = 1\n",
    "            censored = convergence_time_batches.size - np.count_nonzero(convergence_time_batches)\n",
    "            if (censored):\n",
    "                times_value = convergence_time_batches[censored:].reshape(-1)\n",
    "            else:\n",
    "                censored = 1\n",
    "                times_value = convergence_time_batches.reshape(-1)\n",
    "\n",
    "            F = KM_estimator(times_value, censored)\n",
    "\n",
    "            #popt_weibull[0] is alpha\n",
    "            #popt_weibull[1] is gamma    \n",
    "            popt_weibull,_= curve_fit(weib_cdf,xdata=times_value,ydata=np.squeeze(F),bounds=(0,[bound_is,10]),method='trf')\n",
    "            mean = sc.gamma(1+(1./popt_weibull[1]))*popt_weibull[0]\n",
    "        #     print(\"mean\",mean)\n",
    "            std_dev = np.sqrt(popt_weibull[0]**2 * sc.gamma(1+(2./popt_weibull[1])) - mean**2)\n",
    "\n",
    "            std_error = std_dev / np.sqrt(times_value.size)\n",
    "            convergence_time_alpha_dict[num_robots][alpha_str][rho_str]= [mean,std_error] \n",
    "            convergence_time_dict[num_robots][rho_str][alpha_str]= mean\n",
    "        #     print(times_value.shape)\n",
    "            weibull_plot(mean, std_dev, times_value, popt_weibull, F, figLabel, figPath)\n",
    "            plot_heatmap(convergence_time_dict, \"Convergence Time\", conv_time_dir)\n",
    "\n",
    "        else:\n",
    "            ''' Weibull distribution for First Passage Time'''\n",
    "            figPath = ftp_dir+'/'+\"fpt_robots_%s_alpha_%s_rho_%s.png\" % (num_robots, alpha_str, rho_str)\n",
    "            figLabel = \"fpt robots:%s alpha:%s, rho:%s.png\" % (num_robots, alpha_str, rho_str)\n",
    "            fpt = df.values[:,1:2]\n",
    "            censored = fpt.size - np.count_nonzero(fpt)\n",
    "            fpt = fpt[np.argsort(fpt.reshape(-1))]\n",
    "            times_value = fpt[censored:].reshape(-1)\n",
    "\n",
    "\n",
    "            F = KM_estimator(times_value, censored)\n",
    "\n",
    "            #popt_weibull[0] is alpha\n",
    "            #popt_weibull[1] is gamma    \n",
    "            popt_weibull,_= curve_fit(weib_cdf,xdata=times_value,ydata=np.squeeze(F),bounds=(0,[bound_is,10]),method='trf')\n",
    "            mean = sc.gamma(1+(1./popt_weibull[1]))*popt_weibull[0]\n",
    "            mean_fpt_dict[num_robots][rho_str][alpha_str] = mean\n",
    "        #     print(\"mean\",mean)\n",
    "            std_dev = np.sqrt(popt_weibull[0]**2 * sc.gamma(1+(2./popt_weibull[1])) - mean**2)\n",
    "\n",
    "            std_error = std_dev / np.sqrt(times_value.size)\n",
    "            mean_fpt_dict_alpha[num_robots][alpha_str][rho_str]= [mean,std_error] \n",
    "\n",
    "        #     print(times_value.shape)\n",
    "            weibull_plot(mean, std_dev, times_value, popt_weibull, F, figLabel, figPath)\n",
    "            plot_heatmap(mean_fpt_dict,\"Average First Passage Time\", ftp_dir)\n",
    "\n",
    "#     print(\"Convergence Time\")\n",
    "#     print(convergence_time_dict)\n",
    "#     print(\"Average First Passage Time\")\n",
    "#     print(mean_fpt_dict)\n",
    "    print(\"Convergence Time alpha\")\n",
    "    print(convergence_time_alpha_dict)\n",
    "    print(\"FPT alpha\")\n",
    "    print(mean_fpt_dict_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_heatmap(mean_fpt_dict,\"Average First Passage Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_heatmap(convergence_time_dict, \"Convergence Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence_time_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_fpt_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

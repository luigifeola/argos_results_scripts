{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:88% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:88% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import scipy.special as sc\n",
    "from scipy.stats import weibull_min\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weib_cdf(x,alpha,gamma):\n",
    "    return (1 - np.exp(-np.power(x/alpha,gamma)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_weibull(mean, std_dev, temp, popt_weibull):\n",
    "#     #fig=plt.figure(figsize=(16, 14), dpi= 80, facecolor='w', edgecolor='k')\n",
    "#     fig, ax = plt.subplots(figsize=(10, 4), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "#     '''Textbox with mu and sigma'''\n",
    "#     textstr = '\\n'.join((\n",
    "#         r'$\\mu=%.2f$' % (mean, ),\n",
    "#         r'$\\sigma=%.2f$' % (std_dev, )))\n",
    "\n",
    "#     # these are matplotlib.patch.Patch properties\n",
    "#     props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "#     # place a text box in upper left in axes coords\n",
    "#     ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=14,\n",
    "#             verticalalignment='top', bbox=props)\n",
    "\n",
    "\n",
    "#     y_weib=weib_cdf(temp,popt_weibull[0],popt_weibull[1])\n",
    "#     error_weib=np.power(y_weib-np.squeeze(F),2)\n",
    "#     plt.plot(temp,y_weib,'r',linewidth=5,label=\"Weibull Distribution\")\n",
    "#     plt.plot(temp,F,'b',linewidth=5,label=\"K-M stats\")\n",
    "#     plt.legend(loc=4)\n",
    "#     plt.ylim(0,1)\n",
    "#     #label=\"Alpha \"+str(dataset[sample,1])+\" Rho \"+str(dataset[sample,2])+\" Time of First Passage for \"+str(censored)+\"/\"+str(uncensored)+\" censored values\"\n",
    "#     label = figLabel\n",
    "#     plt.title(label)\n",
    "#     plt.xlabel(\"Number of time steps\")\n",
    "#     plt.ylabel(\"Synchronisation probability\")\n",
    "# #     plt.show()\n",
    "#     plt.savefig(figPath)\n",
    "#     plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pd_times(dirPath, experiment_type):\n",
    "    if(experiment_type!=\"times\"):\n",
    "        print(\"experiment_type could be only $times\")\n",
    "        exit(-1)\n",
    "    \n",
    "    num_experiment = len([name for name in os.listdir(dirPath) if (os.path.isfile(os.path.join(dirPath, name)) and (name.endswith('position.tsv')))])\n",
    "    \n",
    "    if(os.path.exists(dirPath+\"/\"+experiment_type+\".pkl\")):\n",
    "#         print(\"Sto cazzo di file esiste\")\n",
    "        return (num_experiment,pd.read_pickle(dirPath+\"/\"+experiment_type+\".pkl\"))\n",
    "    \n",
    "    print(\"Generating pickle times file\")\n",
    "    df = pd.DataFrame()\n",
    "    for filename in os.listdir(dirPath):\n",
    "        if filename.endswith('time_results.tsv'):\n",
    "            df_single = pd.read_csv(dirPath+\"/\"+filename, sep=\"\\t\")\n",
    "            df = df.append(df_single)\n",
    "    \n",
    "    df.to_pickle(dirPath+\"/\"+experiment_type+\".pkl\")\n",
    "    return (num_experiment,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/home/luigi/Documents/scripts/test_scripts/results/results_2020-02-17_robots_10/2020-02-14_robots#10_alpha#2.0_rho#0.0_experiment_1800/times.pkl\"\n",
    "# df = pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_convergence_time(times):\n",
    "    conv_times = np.zeros(times.shape[0])\n",
    "#     print(\"Time shape\", times.shape)\n",
    "    for idx, elem in enumerate(times):\n",
    "        if(elem[0] == 0):\n",
    "            conv_times[idx] = elem[1]\n",
    "        else:\n",
    "            conv_times[idx] = elem.min()\n",
    "    #c_time in ticks \n",
    "#     conv_time_batch = np.append(conv_time_batch, conv_times.max()) \n",
    "    return conv_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = time vector\n",
    "#censored = number o missing values\n",
    "def KM_estimator(data, censored):\n",
    "    '''K-M estimator'''\n",
    "    n_est=np.asarray(range(0,data.size))[::-1] + censored  #array from 29 to 0\n",
    "    RT_sync=[]\n",
    "    for i in range(n_est.size):\n",
    "        if len(RT_sync)==0:\n",
    "            RT_sync.append((n_est[i]-1)/n_est[i])\n",
    "        else:\n",
    "            RT_sync.append(RT_sync[-1]*((n_est[i]-1)/n_est[i]))\n",
    "#     print(RT_sync)\n",
    "    F=1-np.asarray(RT_sync).reshape(-1,1)\n",
    "#     print(F)\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weibull_plot(mean, std_dev, times_value, popt_weibull, F, figLabel, figPath):\n",
    "    fig, ax = plt.subplots(figsize=(20, 8), dpi= 160, facecolor='w', edgecolor='k')\n",
    "    '''Textbox with mu and sigma'''\n",
    "    textstr = '\\n'.join((\n",
    "        r'$\\mu=%.2f$' % (mean, ),\n",
    "        r'$\\sigma=%.2f$' % (std_dev, )))\n",
    "\n",
    "    # these are matplotlib.patch.Patch properties\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    # place a text box in upper left in axes coords\n",
    "    ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=14,\n",
    "            verticalalignment='top', bbox=props)\n",
    "\n",
    "\n",
    "    y_weib=weib_cdf(times_value,popt_weibull[0],popt_weibull[1])\n",
    "    error_weib=np.power(y_weib-np.squeeze(F),2)\n",
    "    plt.plot(times_value,y_weib,'r',linewidth=5,label=\"Weibull Distribution\")\n",
    "    plt.plot(times_value,F,'b',linewidth=5,label=\"K-M stats\")\n",
    "    plt.legend(loc=4)\n",
    "    plt.ylim(0,1)\n",
    "    #label=\"Alpha \"+str(dataset[sample,1])+\" Rho \"+str(dataset[sample,2])+\" Time of First Passage for \"+str(censored)+\"/\"+str(uncensored)+\" censored values\"\n",
    "    label = figLabel\n",
    "    plt.title(label)\n",
    "    plt.xlabel(\"Number of time steps\")\n",
    "    plt.ylabel(\"Synchronisation probability\")\n",
    "    #     plt.show()\n",
    "    plt.savefig(figPath)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(dictionary, title, storage_dir):\n",
    "    for key, value in dictionary.items():\n",
    "        fig=plt.figure(figsize = (12, 8), dpi=80)\n",
    "        dataFrame=pd.DataFrame.from_dict(value)\n",
    "        reversed_df=dataFrame.iloc[::-1]\n",
    "        ax=sns.heatmap(reversed_df, annot = True, fmt = \".2e\", cmap=\"viridis\")\n",
    "        ax.set_title(title+\", num_robots:%s\" % (key))\n",
    "        ax.set_ylabel(\"alpha\")\n",
    "        ax.set_xlabel(\"rho\")\n",
    "#         plt.show()\n",
    "        #Salva su file\n",
    "        file_name=title+\"_%s_robots.png\" % (key)\n",
    "        plt.savefig(storage_dir+'/'+file_name)\n",
    "    #     reversed_df.to_pickle(file_name[:-4] + \".pickle\")\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence Time alpha\n",
      "{'100': {'1.2': {'0.6': [296.84648708149155, 16.174961704438957], '0.9': [308.1495923058286, 17.84967925865103], '0.3': [311.7034402218946, 16.55355070952002], '0.0': [302.71730898237854, 17.926009271762247]}, '2.0': {'0.6': [271.98079630001064, 14.083808402829186], '0.9': [308.60495300360486, 16.47952296438654], '0.3': [298.49465109210394, 15.863277003197538], '0.0': [303.66290269393176, 17.252322449503815]}, '1.6': {'0.6': [291.88416766462774, 15.695716731350624], '0.9': [288.27513464846004, 14.760129785688246], '0.3': [317.4395160471933, 16.871030658021308], '0.0': [286.60084140564834, 15.157109722666679]}}, '50': {'1.2': {'0.6': [1003.5463532986987, 57.246392698734994], '0.9': [1018.929914187105, 58.479688547432886], '0.3': [1007.6655273301122, 51.325965503489485], '0.0': [958.0543876169355, 47.9671784602952]}, '2.0': {'0.6': [895.4686901634549, 42.663810070911566], '0.9': [1038.3591252723318, 51.86991618284786], '0.3': [974.4352235336238, 45.67472211209867], '0.0': [1108.7172207665071, 52.80550284600476]}, '1.6': {'0.6': [904.2346271041355, 49.22363795907875], '0.9': [970.3182934230649, 43.05650699532329], '0.3': [947.388288970896, 47.890805216084026], '0.0': [935.6772825010344, 43.41747685640526]}}, '20': {'1.2': {'0.6': [2893.5776949465367, 134.42071877976633], '0.9': [3422.966187497151, 177.17126418111093], '0.3': [2990.6666529448335, 148.86610296011207], '0.0': [3362.3478065346817, 180.45572561909978]}, '2.0': {'0.6': [2801.3800006989736, 121.49297287798308], '0.9': [3803.777277773733, 206.61906011883903], '0.3': [3350.11396321894, 161.72241256886815], '0.0': [4038.432238643122, 240.48709248090822]}, '1.6': {'0.6': [2668.6350626813232, 124.14276314378696], '0.9': [3524.9444584653356, 202.76910856496403], '0.3': [3010.867830251771, 155.27111151527498], '0.0': [3614.7086675080886, 200.3215862738644]}}, '10': {'1.2': {'0.6': [4943.890877978175, 267.4057824929987], '0.9': [6443.490659996681, 335.00979822263264], '0.3': [5961.50943241874, 291.95915299167103], '0.0': [6353.353107248888, 348.95725389076415]}, '2.0': {'0.6': [4683.47077757047, 232.60493097667305], '0.9': [8415.060984193433, 443.0663748911313], '0.3': [6722.253468917855, 355.432677865307], '0.0': [8799.448152700583, 482.3648064296094]}, '1.6': {'0.6': [4747.266949499249, 245.648165897575], '0.9': [7555.8217084629205, 400.9036863659445], '0.3': [6504.395966163576, 316.58325987553786], '0.0': [7466.151714161362, 381.5528411690255]}}}\n",
      "FPT alpha\n",
      "{'100': {'1.2': {}, '2.0': {}, '1.6': {}}, '50': {'1.2': {}, '2.0': {}, '1.6': {}}, '20': {'1.2': {}, '2.0': {}, '1.6': {}}, '10': {'1.2': {}, '2.0': {}, '1.6': {}}}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    robots = [10, 20, 50, 100]\n",
    "    mean_fpt_dict = dict()\n",
    "    convergence_time_dict = dict()\n",
    "    #WARNING : you can remove convergence_time_alpha_dict using just convergence_time_dict\n",
    "    convergence_time_alpha_dict = dict()\n",
    "    mean_fpt_dict_alpha = dict()\n",
    "    #When conv_time_estimation==Flase -> fpt estimation\n",
    "    conv_time_estimation = True\n",
    "    bound_is=75000\n",
    "\n",
    "    from datetime import date\n",
    "    today = date.today()\n",
    "\n",
    "    script_dir = os.path.abspath('')\n",
    "    results_dir = os.path.join(script_dir, 'Plots/'+str(today)+'/Weibull')\n",
    "\n",
    "    if not os.path.isdir(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "\n",
    "\n",
    "    conv_time_dir = os.path.join(results_dir, 'convergence_time')\n",
    "\n",
    "    ftp_dir = os.path.join(results_dir, 'first_passage_time')\n",
    "\n",
    "    if not os.path.isdir(conv_time_dir):\n",
    "        os.makedirs(conv_time_dir)\n",
    "    if not os.path.isdir(ftp_dir):\n",
    "        os.makedirs(ftp_dir)\n",
    "        \n",
    "    for r in robots:    \n",
    "        folder = \"/home/luigi/Documents/scripts/test_scripts/results/results_2020-02-21_rob_%s\" %(r)\n",
    "        \n",
    "\n",
    "        if not os.path.isdir(folder):\n",
    "            print(\"folder is not an existing path\")\n",
    "            exit(-1)\n",
    "\n",
    "\n",
    "        for dirName, subdirList, fileList in os.walk(folder):\n",
    "            num_robots = \"0\"\n",
    "            rho = -1.0\n",
    "            alpha = -1.0\n",
    "            elements=dirName.split(\"_\")\n",
    "            for e in elements:\n",
    "                if e.startswith(\"robots\"):\n",
    "                    num_robots=e.split(\"#\")[-1]\n",
    "                    if(num_robots not in mean_fpt_dict):\n",
    "                        mean_fpt_dict[num_robots]=dict()\n",
    "                        convergence_time_dict[num_robots]=dict()\n",
    "                        convergence_time_alpha_dict[num_robots]=dict()\n",
    "                        mean_fpt_dict_alpha[num_robots]=dict()\n",
    "\n",
    "                if(e.startswith(\"rho\")):\n",
    "                    rho=float(e.split(\"#\")[-1])\n",
    "                if(e.startswith(\"alpha\")):\n",
    "                    alpha=float(e.split(\"#\")[-1])\n",
    "\n",
    "            if(num_robots == \"0\" or rho == -1.0 or alpha == -1):\n",
    "                continue\n",
    "\n",
    "        #     print(dirName)\n",
    "        #     print(num_robots)\n",
    "        #     print(mean_fpt_dict)\n",
    "\n",
    "            rho_str=str(rho)\n",
    "            alpha_str=str(alpha)\n",
    "        #     print(\"rho\", rho_str)\n",
    "        #     print(\"alpha\", alpha_str)\n",
    "            if(rho_str not in mean_fpt_dict[num_robots]):\n",
    "                mean_fpt_dict[num_robots][rho_str]=dict()\n",
    "        #         print(mean_fpt_dict)\n",
    "\n",
    "                convergence_time_dict[num_robots][rho_str]=dict()\n",
    "            \n",
    "            if(alpha_str not in convergence_time_alpha_dict[num_robots]):\n",
    "                convergence_time_alpha_dict[num_robots][alpha_str]=dict()\n",
    "                mean_fpt_dict_alpha[num_robots][alpha_str]=dict()\n",
    "        #         print(total_dict)\n",
    "            #WARNING : di mettere alpha probabilmente non ce n'è bisogno\n",
    "        #     if(alpha_str not in total_dict[num_robots][rho_str]):\n",
    "        #         total_dict[num_robots][rho_str][alpha_str]=dict()\n",
    "        #         mean_fpt_dict[num_robots][rho_str][alpha_str]=dict()\n",
    "        #         convergence_time_dict[num_robots][rho_str][alpha_str]=dict()\n",
    "\n",
    "\n",
    "            (num_experiment, df) = load_pd_times(dirName, \"times\")\n",
    "\n",
    "\n",
    "            df_times = df.values[:,1:]\n",
    "            convergence_times = evaluate_convergence_time(df_times)\n",
    "        #     print(dirName)\n",
    "        #     print(convergence_times.shape)\n",
    "\n",
    "            \n",
    "        #     print(df_times.shape)\n",
    "        #     print(\"num experiments: \", num_experiment)\n",
    "\n",
    "            \n",
    "            if(conv_time_estimation):\n",
    "                '''Weibull distribution for Convergence Time'''\n",
    "\n",
    "                #get the time in whitch each robot has at least info about the target\n",
    "                convergence_time_batches = np.amax(convergence_times.reshape(num_experiment,-1) , axis=1) \n",
    "        #         print(dirName)\n",
    "\n",
    "                #order convergence_time_batches in increasing order\n",
    "                convergence_time_batches = convergence_time_batches[np.argsort(convergence_time_batches)]\n",
    "        #         print(convergence_time_batches.shape)\n",
    "        #         print(convergence_time_batches)\n",
    "                figPath = conv_time_dir+'/'+\"conv_time_robots_%s_alpha_%s_rho_%s.png\" % (num_robots, alpha_str, rho_str) \n",
    "                figLabel = \"Convergence Time robots:%s alpha:%s, rho:%s.png\" % (num_robots, alpha_str, rho_str)\n",
    "        #         censored = 1\n",
    "                censored = convergence_time_batches.size - np.count_nonzero(convergence_time_batches)\n",
    "                if (censored):\n",
    "                    times_value = convergence_time_batches[censored:].reshape(-1)\n",
    "                else:\n",
    "                    censored = 1\n",
    "                    times_value = convergence_time_batches.reshape(-1)\n",
    "                    \n",
    "                F = KM_estimator(times_value, censored)\n",
    "\n",
    "                #popt_weibull[0] is alpha\n",
    "                #popt_weibull[1] is gamma    \n",
    "                popt_weibull,_= curve_fit(weib_cdf,xdata=times_value,ydata=np.squeeze(F),bounds=(0,[bound_is,10]),method='trf')\n",
    "                mean = sc.gamma(1+(1./popt_weibull[1]))*popt_weibull[0]\n",
    "            #     print(\"mean\",mean)\n",
    "                std_dev = np.sqrt(popt_weibull[0]**2 * sc.gamma(1+(2./popt_weibull[1])) - mean**2)\n",
    "\n",
    "                std_error = std_dev / np.sqrt(times_value.size)\n",
    "                convergence_time_alpha_dict[num_robots][alpha_str][rho_str]= [mean,std_error] \n",
    "                convergence_time_dict[num_robots][rho_str][alpha_str]= mean\n",
    "            #     print(times_value.shape)\n",
    "                weibull_plot(mean, std_dev, times_value, popt_weibull, F, figLabel, figPath)\n",
    "                plot_heatmap(convergence_time_dict, \"Convergence Time\", conv_time_dir)\n",
    "\n",
    "            else:\n",
    "                ''' Weibull distribution for First Passage Time'''\n",
    "                figPath = ftp_dir+'/'+\"fpt_robots_%s_alpha_%s_rho_%s.png\" % (num_robots, alpha_str, rho_str)\n",
    "                figLabel = \"fpt robots:%s alpha:%s, rho:%s.png\" % (num_robots, alpha_str, rho_str)\n",
    "                fpt = df.values[:,1:2]\n",
    "                censored = fpt.size - np.count_nonzero(fpt)\n",
    "                fpt = fpt[np.argsort(fpt.reshape(-1))]\n",
    "                times_value = fpt[censored:].reshape(-1)\n",
    "\n",
    "\n",
    "                F = KM_estimator(times_value, censored)\n",
    "\n",
    "                #popt_weibull[0] is alpha\n",
    "                #popt_weibull[1] is gamma    \n",
    "                popt_weibull,_= curve_fit(weib_cdf,xdata=times_value,ydata=np.squeeze(F),bounds=(0,[bound_is,10]),method='trf')\n",
    "                mean = sc.gamma(1+(1./popt_weibull[1]))*popt_weibull[0]\n",
    "                mean_fpt_dict[num_robots][rho_str][alpha_str] = mean\n",
    "            #     print(\"mean\",mean)\n",
    "                std_dev = np.sqrt(popt_weibull[0]**2 * sc.gamma(1+(2./popt_weibull[1])) - mean**2)\n",
    "\n",
    "                std_error = std_dev / np.sqrt(times_value.size)\n",
    "                mean_fpt_dict_alpha[num_robots][alpha_str][rho_str]= [mean,std_error] \n",
    "\n",
    "            #     print(times_value.shape)\n",
    "                weibull_plot(mean, std_dev, times_value, popt_weibull, F, figLabel, figPath)\n",
    "                plot_heatmap(mean_fpt_dict,\"Average First Passage Time\", ftp_dir)\n",
    "\n",
    "#     print(\"Convergence Time\")\n",
    "#     print(convergence_time_dict)\n",
    "#     print(\"Average First Passage Time\")\n",
    "#     print(mean_fpt_dict)\n",
    "    print(\"Convergence Time alpha\")\n",
    "    print(convergence_time_alpha_dict)\n",
    "    print(\"FPT alpha\")\n",
    "    print(mean_fpt_dict_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_heatmap(mean_fpt_dict,\"Average First Passage Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_heatmap(convergence_time_dict, \"Convergence Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence_time_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_fpt_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5.2 64-bit ('argos': virtualenv)",
   "language": "python",
   "name": "python35264bitargosvirtualenv7d4f7d92e2084569ac79cc76ee421ade"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
